---
layout: post
title: "[부스트캠프 AI Tech 3기] 16주차 정리 & 회고"
categories:
  - BoostCamp
tags:
  - 부스트캠프
  - AI
  - Deep Learning
  - T5
  - NLP
  - MRC
  - Retriever
---
![Untitled](/assets/img/AITech로고.png)

# ✏️학습정리

## Reducing Training Bias

- Definition of Bias
    - Bias in learning
        - 학습할 때 overfitting 방지, 사전 지식 주입을 위해 특정 형태의 함수를 선호하는 것(inductive bias)
    - A Biased World
        - 현실 세계 자체의 편향성(historical bias)
        - 성별과 직업 사이의 관계 등 표면적인 상관관계로 인해 원치 않는 속성이 학습되는 것(co-occurrence bias)
    - Bias in Data Generation
        - 입,출력 정의 방식 때문에 생기는 편향성(specification bias)
        - 데이터 샘플링 방식 때문에 생기는 편향성(sampling bias)
        - 어노테이터의 특정 때문에 생기는 편향성(annotator bias)
    - 대표적인 예
        - Gender bias - 특정 성별과 행동을 연관시켜서 예측 오류가 발생
        - Sampling bias - 표본 수집 단계에서 편향성이 발생하는 경우
- Bias in ODQA
    - Training bias in reader model
        - reader 모델이 한정된 데이터셋에서만 학습된다면 → reader는 항상 정답이 문서 내에 포함된 데이터쌍만(positive) 보게 됨 → inference 시 기존 데이터와 많이 다른 문서를 준다면 독해능력이 떨어질 것이고, 결과적으로 정답 도출에 실패할 것
    - How to mitigate training bias
        1. training negative examples: 훈련시 잘못된 예시를 보여줘야 retriever가 negative한 내용들을 멀리 배치할 수 있음
            1. negative도 완전 다른 것과 비슷한 negative에 대한 차이 고려 필요
            2. Corpus 내에서 랜덤하게 샘플링
            3. 좀 더 헷갈리는 negative를 뽑기: 높은 매칭 스코어를 가지지만, 답을 포함하지 않는 샘플, 같은 문서에서 나온 다른 Passage/Question 선택
        2. Add no answer bias: 입력 시퀀스 길이 + 1의 토큰이 있다고 생각 → 마지막 위치가 가장 확률이 높을 때 no answer로 취급
- Annotation Bias from Datasets
    - Annotation bias: 질문 하는 사람이 답을 모를 경우에 질문을 하는 경우가 이상적이지만, 질문을 하는 사람이 이미 답을 알고 있는 경우가 Annotation 과정에서 많이 발생
    - Dealing with annotation bias
        - natural questions: supporting evidence가 주어지지 않은 실제 유저의 질문을 샘플링
    - ODQA 자체에 걸맞지 않은 질문을 만들 수도 있으니 주의

## Closed-book QA with T5

- Closed-book Question Answering
    - 모델이 이미 사전학습으로 대량의 지식을 학습했다면, 그 사전학습 언어모델 자체가 이미 하나의 knowledge storage라고 볼 수 있다 → 굳이 다른 곳에서 지식을 가져올 필요가 없을 것이다
    - GPT-2 때부터 big model이 natural question에도 어느정도 대답을 할 수 있음을 보임
- Text-to-Text Format
    - Closed-book QA는 Generation-based MRC와 유사
        - 입력에 지문 없이 질문만 들어간다는 것이 차이점
    - text-to-text: input으로 text를 받아서 output으로 새로운 text를 생성하는 문제
        - 다양한 task-specific prefix를 input에 추가
    - 모델의 형태는 사실상 BART의 상위호환
    - T5: Text-to-Text Format으로 거의 모든 text 문제를 해결하도록 세팅된 seq2seq transformer 모델

## QA with Phase Retrieval

- Current Limitation of Retriever-Reader approach
    - Error Propagation: Reader에 전달된 passage에 정답이 없을수도 있음
    - Query-dependent encoding: query에 따라 정답이 되는 answer span에 대한 encoding이 달라짐
- Phrase Retrieval
    - 베이스 지식으로 보유한 문서들을 phrase 단위로 미리 벡터화, 이 벡터들과 들어온 query 질문과의 유사성을 체크하여 정답 phrase를 반환하는 방식
- Dense-sparse Representation for Phrases
    - Dense, Sparse 방식 둘 다 장단점이 있다
    - 각각에서 벡터를 획득하여 Phrase Vector로 활용

# 📄피어세션 정리

- 월: 8~10강 강의 수강
- 화: 팀 논문 발표, 각자 할 일 정하기
- 수: 멘토링, 오피스아워
- 목: 어린이날
- 금: 이고잉님 특강

# 🤔학습 회고

- 잘했던것, 좋았던것, 계속할것
    - 일찍 논문발표 마감하고 본 과제로 돌아온 것,
- 잘못했던것, 아쉬운것, 부족한것 -> 개선방향
    - 블로그 리뉴얼을 다 하지 못했음 → 이번 주에 적어도 남에게 보여줄 수준으로 완성하기
- 도전할 것, 시도할 것
    - 블로그 리뉴얼 완료하기, 학습 데이터 다양화 시도하기
- 키워드(공부한 것,알게된 것, 느낀 점)
    - negative sampling, 통계학적 관점에서 접근한 automatic data labeling 기법