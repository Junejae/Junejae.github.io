---
layout: post
title: "[부스트캠프 AI Tech 3기] 12주차 정리 & 회고"
categories:
  - BoostCamp
tags:
  - 부스트캠프
  - AI
  - Deep Learning
  - BERT
  - NLP
  - KLUE
  - RoBERTa
  - Transformer
  - Relation Extraction
---
![Untitled](/assets/img/AITech로고.png)

## 🧭학습목표

### 팀 공통 학습목표

- Text Data Augmentation 경험
- Github으로 협업하는 방법 익히기
- Huggingface 자유롭게 사용하기

### 개인 학습

- 한글 text data augmentation 조사 & 적용
- 쉘스크립트 도입으로 실험 간편 & 자동화
- 체계적인 WandB 세팅으로 실험 추적 편리성 추구
- VScode의 git 관리 툴을 이용한 코드 버전 관리
- 공식문서를 다독하며 Huggingface 기반 코드 커스터마이징

### 공동 학습

- 데일리 스크럼, 피어세션을 통해 팀원의 진척도 확인과 트러블슈팅
- 과거 경험과 논리에 기반한 인사이트 제공으로 학습 방향 조정
- 팀 슬랙 채널을 이용한 깃허브 수정 기록 관리, 일일 제출 수요 조사
- Validation set, metric 고정으로 팀 내 분석 방법 통일
- 자잘한 실험은 개인 로그, 중요한 실험만 팀 로그에 기록하며 실험 기록 아카이빙

## 📖사용한 지식 & 기술

- Pre-trained LM: (KLUE)Bert, (KLUE)RoBERTa, koElectra
- Loss Function: Cross-Entropy, Focal Loss
- Transfer Learning 기법: Fine-Tuning
- 데이터셋 재정립: Sklearn의 StratifiedShuffleSplit을 이용한 라벨 별 균등 비율 분리 → validation set 제작, 중복 데이터 제거, 미스라벨링 교정
- Augmentation: 모음 변형에 의한 노이즈, 음운변화에 의한 노이즈, 한→영→한 Backtranslation
- Metric: F1 Score, AUPRC
- Ensemble: Soft Voting
- Hyperparameter Tuning: batch size, epoch, learning rate, warmup rate, dropout, weight decay

## 🧑🏻‍🎓결과 ⇒ 깨달음

- RoBERTa-large 모델에 backtranslation을 적용한 증강 데이터가 포함된 학습 데이터로 최적의 하이퍼 파라미터를 세팅 하여 fine-tuning 한 결과물이 팀 내 단일 모델 기준 2위를 달성하였다.
    - 논문을 기반으로 선택한 적절한 모델을 사용하면, 하이퍼 파라미터만 적절히 세팅 해 줘도 높은 퍼포먼스를 달성할 수 있음을 깨달았다.
- Backtranslation을 적용한 증강 데이터로 학습한 모델을 앙상블에 넣었을 때 효과가 있었다.
    - 학습한 데이터만 달라져도 모델이 데이터를 바라보는 시각이 달라짐을 확인할 수 있었다.

## 🛠️새롭게 시도한 변화 ⇒ 효과

- 대회 초창기에 EDA와 간단한 모델을 통해 테스트 하면서 최대한 리더보드와 유사한 기준점이 되는 Metric을 확립하였다.
    - 실험의 신뢰성을 확보할 수 있었고, 동료들과의 커뮤니케이션에도 도움이 되었다
- 새로운 라이브러리, 환경을 사용하는 것에 거부감을 가지지 않았다.
    - huggingface 뿐만 아니라, ktextaug나 googletrans 같은 데이터 증강에 필요한 외부 라이브러리를 빠르게 도입하여 작업시간을 단축할 수 있었다.
- 새로운 방법을 제안하거나 반대할 때, 논리 이외에도 실증을 통해서 증명하려 노력했다.
    - 증명을 위한 실험 과정에서 새로운 결론이 도출 → 추가 실험 등의 꼬리에 꼬리를 무는 유기적인 실험이 저절로 구성되었고, 이는 남을 설득할 때 더 튼튼한 근거가 되었다.
- 외부 함수를 쓰기 전에 기술 문서와 다른 사람의 코드를 보며 충분히 이해한 후 사용하려 노력했다.
    - 함수를 잘못 써서 일어나는 사고가 현저히 감소하였고, 코드에 대한 이해도 또한 상승하여 남을 더 잘 도와줄 수 있었다.

## 🏗️실수 & 한계 ⇒ 개선 방안

- 대회 끝까지 완벽하게 독립성이 확보된 eval 데이터셋 분리에 실패했다.
    - 다음 프로젝트부턴 하드코딩을 하는 한이 있더라도 데이터에 쓰는 시간을 늘려야겠다.
- Augmentation 기법 중 가장 간단한 backtranslation을 그냥 토론 게시판만 보면서 entity 손상 가능성으로 인한 수율 불안정성을 두려워 해서 시도조차 안 하려 했다.
    - 결과가 불안해 보이는 시도라도 초반에 최대한 해 보면서 인사이트를 얻으려 노력해야겠다.
- 깃허브 코드 관리를 팀 단위로 유기적으로 진행하려 했지만, 마지막 3주차에선 거의 하지 못했다.
    - 프로젝트 그라운드 룰로 매 저녁마다 코드 업데이트를 시행하는 것을 고려 중이다.
- 쉘스크립트 도입을 통한 실험 간편화까진 고안했지만, 이를 통한 실험 자동화로 밤새 실험을 많이 돌릴 수 있단 사실을 뒤늦게 알았다.
    - 변화가 가져온 이득에 만족하며 안주하지 않고, 더더욱 발전하려 노력하는 자세를 길러야겠다.

## 🆕다음 프로젝트에서 새롭게 시도해볼 것들

- 컨피그 파일을 이용한 하이퍼 파라미터 세팅
- 쉘스크립트를 사용한 실험 자동화
- 더 정밀한 EDA를 통한 독립성이 완전 보장된 eval 셋 분리
- 더욱 체계화된 팀 코드 관리