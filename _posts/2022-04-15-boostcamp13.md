---
layout: post
title: "[부스트캠프 AI Tech 3기] 13주차 정리 & 회고"
categories:
  - BoostCamp
tags:
  - 부스트캠프
  - AI
  - Deep Learning
  - NLP
  - Dataset
---
![Untitled](/assets/img/AITech로고.png)

# ✏️학습정리

## 데이터 제작의 A to Z

- 데이터 제작의 피, 땀, 눈물
    - 프로젝트에서 서비스를 기획하고 그에 맞는 데이터를 준비하는 단계가 전체의 80%다
- 데이터 구축 과정
    - 원시 데이터 확보
    - 가공 프로세스 확립
    - 지침 작성
    - 가공
    - 검수
- 초보자는 이미 정제되어 있는 데이터를 보면서 감을 익혀보자
- 데이터 설계
    - 데이터 유형
        - 소리, 텍스트, 이미지, 영상 등의 유형
    - 데이터 in/out 형식
        - 다양한 확장자를 가지는 형식이 존재
    - 데이터별 규모, 구분방식
        - 학습, 검증, 평가 셋 기준을 정해야 함
    - 데이터 주석 유형
        - 경우에 따라 다양하게 라벨링을 할 수 있다.
- 데이터 수집-가공 설계
    - 원시 데이터 수집 방식
        - 전산화, 스크래핑, 작업자 작성, 모델을 통해 생성 등 → 기준을 정해야 함
    - 작업자 선정
        - 난이도에 따라 전문가를 쓸지, 크라우드 소싱을 할지 결정 → 단가 차이가 남
    - 데이터 구축 및 검수 설계
        - 파일럿 구축 → 본 구축 프로세스
    - 데이터 구축 및 가공
        - 파일럿: 설계 시 발견 못한 에러 해결, 테스트를 통해 작업자 선정
        - 본 구축: 작업 일정, 작업자 관리 → 중간 검수로 데이터 품질 관리
    - 데이터 검수 및 분석
        - 평가 지표 설정
        - 전문가 평가 및 분석
        - 자동 평가 및 분석
- 자연어처리 데이터
    - 자연어: 일상적 언어 그 자체
    - 인공어: 여러 사람의 목적이나 의도에 따라 만든 언어 또는 컴퓨터 언어
    - 자연어처리: 사람의 언어를 컴퓨터가 알아듣도록 처리하는 인터페이스 역할, 최종적으론 컴퓨터가 사람의 언어를 이해하고 여러 문제를 해결
    - 언어학, AI, 텍스트 마이닝의 포괄적 이해가 필요

## 자연어처리 데이터 기초

- 인공지능 모델 개발을 위한 데이터
    - 데이터의 종류
        - 말뭉치 류: 실제 텍스트 기반의 데이터
        - 사전/데이터베이스 류: 텍스트 분석 시 참조로 사용되는 자원
    - 과제와 데이터 자체는 초창기부터 거의 변함이 없으나, 기술만이 발전해왔음
    - 언어모델 평가를 위한 벤치마크 등장
        - GLUE - 자연어 이해
        - Super GLUE - 고난도 자연어 이해
        - KILT - 지식기반 자연어 이해
        - GEM - 자연어 생성
    - 벤치마크 구성
        - 평가, 검증, 훈련 데이터 제공
        - 기본적인 베이스라인 코드 제공
        - 과제, 평가지표, 리더보드 제공
- 데이터 관련 용어 정리
    - 텍스트: 본문이나 원문, 문장이 모여서 이루어진 한 덩어리의 글
    - 말뭉치(corpus, corpora): 어떤 기준으로든 한 덩어리로 볼 수 있는 말의 뭉치
    - 데이터: 컴퓨터가 처리할 수 있는 정보
    - 주석: tag, label, annotation
    - 언어학의 연구 분야: 형태론, 통사론, 텍스트 언어학, 말뭉치 언아학 등을 집중해서 고려
    - 텍스트 데이터의 기본 단위
        - 영어 기본단위: 단어, 띄어쓰기 단위
        - 한국어 기본단위: 어절
        - 한국어의 단어는 9품사로 분석되는데, 이 중 조사는 체언과 붙어 사용되기에 띄어쓰기 단위가 단어의 단위와 일치하지 않음
        - 품사: 단어를 문법적 성질에 따라 묶어 놓은 것
        - 품사 분류 기준: 의미, 기능, 형식
    - 타입과 토큰
        - 토큰: 언어를 다루는 가장 작은 기본 단위: 단어, 형태소, 서브워드 등의 기준이 있음
        - 타입: 토큰의 대표 형태
    - N-gram
        - 연속된 N개의 단위
    - 표상 - representation
        - 대표로 삼을 만큼 상징적인 것
- 자연어처리 데이터 형식
    - HTML: 웹페이지를 나타내는 마크업 언어
    - XML: 사람과 기계가 동시에 읽기 편한 구조로 짜여진 마크업 언어, 사용자가 임의로 태그를 정의할 수 있음
    - JSON, JSONL: 속성-값 쌍, 키-값 쌍으로 이루어진 데이터 형식
    - CSV: 필드를 쉼표로 구분한 텍스트 데이터
    - TSV: 필드를 탭으로 구분한 텍스트 데이터, 구분자 차이
- 공개 데이터
    - 케글이나 데이콘 등의 경진대회 공개 데이터 형식에 따라 공부하는 것을 추천
    - 국가 공공 데이터도 존재
    - 오픈소스 벤치마크 데이터도 존재

## 자연어처리 데이터 소개

- 국내 언어 데이터 구축 프로젝트
    - 97년부터 국가 주도로 국립국어원에서 시작한 것이 시초
    - 5년가랑 공백기
    - 이후 다시 다른 국가기관 주도로 새로운 프로젝트 개시
    - 알파고 쇼크를 기점으로 국립국어원과 민간차원 프로젝트 신규 개시
- 21세기 세종계획 & 모두의 말뭉치
    - 21세기 세종계획
        - 98년부터 10년간 진행
        - 한국의 국어 정보화 중장기 발전 계획
        - XML 형식
    - 모두의 말뭉치
        - 21세기 세종계획 이후 진행된 국가프로젝트
        - 일상 대화 등의 원시 말뭉치를 수집해서 배포
        - JSON 형식
- 엑소브레인
    - 언어처리 AI 개발을 위해 만든 프로젝트
    - TTA 표준안도 마련됨
    - ERTI 주도
    - 장학퀴즈에서 우승하는 것이 첫 목표였음
- AI허브
    - AI 학습에 필요한 인프라 제공
    - JSON, 엑셀 등의 형식
    - 실제 산업계 수요를 반영
- 민간 주도 데이터셋
    - KLUE: 한국어 이해 능력 평가 벤치마크, 순수한 한국어 원시 말뭉치를 기반으로 가공
    - KorQuAD: 위키 데이터 기반, 한국어 기계독해 데이터셋
    - KorNLU: 자연어 추론과 문장 의미 유사도의 영어 데이터셋을 기계번역해서 공개
- 질의응답
    - SQuAD: 위키 데이터 기반으로 제작, 기계독해, 질의응답 데이터
- 기계번역
    - WMT: 기계번역 학회에서 공개한 다국어 번역 데이터셋, 두 언어간 번역의 형식을 가짐
- 요약
    - CNN/Daily Mail: 추상 요약 말뭉치, 기사와 사람이 기사를 요약한 요약문의 짝으로 구성
    - 저작권 문제로 URL 리스트 제공
- 대화
    - DSTC: 00년대 초반부터 진행된 대화 시스템 챌린지
    - Wizard of Oz: WoZ 방식으로 수집된 데이터셋
    - UDC: 우분투 플렛폼 포럼의 대화를 수집한 데이터

## 원시 데이터의 수집과 가공

- 원시 데이터의 정의
    - 주석 단계를 거치지 않은 상태의 원하는 도메인에 맞게 수집한 데이터
    - 목적에 맞게 전처리 과정을 거쳐 가공이 되어야 활용 가능
    - 스크래핑, 수작업, 기존 데이터 활용, 생성모델 이용 등의 수집루트가 존재
    - 원시 텍스트 데이터의 종류
        - 문어: 신문기사, 소설, 논문 등
        - 구어: 일상 대화, 방송 대본 등
        - 웹: SNS, 커뮤니티, 이메일 등
    - 원시 텍스트 데이터의 메타 정보
        - 텍스트를 설명하는 정보, 사전에 정해진 양식에 맞춰 기록
- 원시 데이터 수집 시 고려 사항
    - 획득 가능성: 시간, 난이도, 비용에 따라 만족스런 획득이 불가능한 케이스가 존재
    - 데이터 균형과 다양성: 레이블에 따라 다양한 데이터가 균형있게 확보되어야 하는 경우
    - 신뢰성: 품질이 신뢰할 수 있는 수준인지 검토해야 함, 특히 아웃소싱 할 때
    - 법 제도 준수: 저작권, 개인정보보호법 등에 따라 적절히 법적, 기술적 조치를 취해야 함
        - 원시 데이터에 주석 작업을 거칠 경우 2차 저작물로 간주
        - 이 경우, 라이센스는 원시 데이터를 따른다
        - 원시 데이터의 라이센스에 따라 주석 작업 자체가 불가능할 수도 있다
    - 데이터 윤리: 인공지능 윤리 가이드라인 등을 따라 법 제도 외에도 선을 넘지 않는 것이 필요
- 원시 데이터 전처리
    - 전처리 단계
        - 추출 대상 확인
        - 정제 대상 확인
        - 불필요 요소 제거 및 변환
- 원시 데이터의 가공 - 주석 도구
    - 주석 작업: 원시 데이터를 가공하여 원하는 정보를 부착하는 작업
    - 주석 작업에 다양한 도구가 사용됨
    - 구글 스프레드 시트: 여러명의 작업자가 동시 작업 가능
    - 구글 폼: 단순한 분류 문제에 탁월, 결과를 구글 스프레드 시트로 바로 확인 가능, 작업자 모집에도 사용 가능
    - Brat: 오픈 소스 데이터 주석 툴
    - Doccano: NER, 감성분석, 기계 번역 등의 주석 기능 제공
    - Tagtog: 웹 기반 주석 툴, 무료 이용할 시 데이터를 전체 공개 해야 함
    - [aihub.or.kr](http://aihub.or.kr) 참조

## 데이터 구축 작업 설계

- 데이터 구축 프로세스
    - 과제 정의 - 수집 - 정제 - 주석 -학습 -검수 - 주석 - 학습 - 검수 - ...
    - 예시
        - 파일럿 구축 - 파일럿 검수 - 1차 구축 - 1차 검수 - 2차 구축 - 최종 검수
- 데이터 주석
    - 데이터 주석 유형
        - 분류: 감성 분석, 주제 분류, 자연어 추론 등, 구축 난이도는 보통 낮은 편
        - 특정 범위(span) 주석: NER, 텍스트의 일부에 특정 레이블을 주석, 개체명, 형태 분석 등, 과제에 따라 구축 난이도가 천차만별
        - 대상 간 관계 주석: 개체명 연결, 관계 추출, 구문 분석 등, 두 단계에 걸친 구축 탓에 난이도가 높은 편
        - 텍스트 생성: 번역, 대화문, 요약 등, 인풋 텍스트에 대한 아웃풋을 생성하는 유형
        - 복합 유형: 앞선 유형들을 복합적으로 사용하여 다양한 정보를 레이블링, 질의 응답, 슬롯 필링 대화 등
- 데이터 검수
    - 가이드라인 정합성: 주석 절차와 내용이 가이드라인에 부합하는지
    - 데이터 형식: 형식이 제대로 맞는지 확인
    - 통계 정보: 데이터 분포 등의 통계치 확인
    - 모델 성능 확인: 모델 학습을 통해 결과값을 확인
    - 오류 원인 분석
        - 구축방법 측면: 통제 미흡으로 인해 다양한 오류 생성
        - 가이드라인 측면: 작업자간 가이드라인 미흡으로 인한 일관성 위배
        - 데이터셋 측면: 설계 부족, 정확성 위배, 구축 중복 등
        - 학습모델 측면: 모델과 데이터가 매칭이 안되거나, 애초에 잘못된 학습모델 선정
    - 검수 유형
        - 표본 추출
        - 전수 검사
    - 데이터 평가
        - 작업자 간 일치도 확인: Task별로 가능여부가 다름, cohen, fleiss
        - 모델 평가: accuracy, precision, recall, f1
- 데이터 구축 프로세스 설계 시 유의 사항
    - 구축 기간은 넉넉하게
    - 검수에 시간을 넉넉히
    - 검수 내용 반영에 대한 계획을 세우기
    - 품질 미달의 보완책을 마련
    - 작업 난이도에 따라 인력을 산정, 모집, 관리를 계획
    - 단계별 작업의 주체를 고려
    - 단계별 검수 유형을 지정
    - 외부인력과 자원을 쓸 경우, 기본 단가 산정 기준을 잘 세워서 비용 산정에 도움을 줘야 함

## 데이터 구축 가이드라인 작성 기초

- 가이드라인의 유형
    - 목적
        - 수집, 주석, 검수를 위한 가이드라인
        - 주석을 위한 가이드라인이 필수
    - 제시 방식
        - 문서형, 화면 노출형, 튜토리얼형
- 가이드라인의 구성 요소
    - 목적 정의
    - 고려 사항
    - 사용 용어 정의
    - 이외에도 목적에 따른 다양한 가이드라인을 제시하여야 함
- 가이드라인의 버전 관리
    - 가이드라인은 지속적으로 개선되어야함
    - 전후 변화를 볼 수 있도록 버전 관리를 해 주는 것이 좋음
- 가이드라인 작성 도구
    - Google Docs: 공유가 자유롭고, 중간저장이 기민하다
    - Notion: 다양한 페이지 형식을 제공, 기본적으로 마크다운 언어를 지원
    - 워드 및 한글: 정부 사업을 하는 경우, 쓸 일이 없다 싶어도 정부사업을 접하면 필연적으로 쓰게 됨
    - 그 외: 레이블링 에이전시에서 제공하는 도구, 위키 등
- 가이드라인 작성 시 유의 사항
    - 유형별 특성을 이해하고, 그에 맞는 정보를 작성
    - 작업자의 이해도를 고려하여 작성
    - 사전에 작업자에게 공개해야 하는 필수 정보와 부가 정보를 인지해야 함
    - 가이드라인 구성 요소의 배치를 고려
    - 작업자의 가독성을 고려

## 관계 추출 과제의 이해

- 개체명 인식: Named Entity Recognition
    - 문장을 분석하여 출현한 개체명의 경계를 인식, 각 개체명에 해당하는 태그를 라벨링
- 관계 추출: Relation Extract
    - 두 개체간의 관계를 특정
- 개체명 연결: Entity Linking
    - 개체명을 인식 → 모호성을 해소
    - 개체명을 지식 베이스와 연결
- NER 데이터 구축 시 문제점
    - 2개 이상의 태그로 라벨링 될 수 있는 개체명
    - 라벨링 대상의 범주
    - 한국어 데이터 현실에 맞지 않는 주석
    - 지식 베이스의 활용
- EL 데이터 구축 시 문제점
    - 적합한 지식 베이스 선정의 문제
- 이런 데이터를 만드는 이유
    - 비정형화된 텍스트에서 정보를 추출하여 구조화 하려는 것
    - 제작 과정에 지식 베이스가 활용되기도 하고, 결과물이 지식 베이스가 되기도 함
- 지식 그래프
    - 개체 관의 관계를 그래프 구조로 표현

## 관계 추출 관련 논문 읽기

- Position-aware Attention and Supervised Data Improve Slot Filling
    - TACRED 데이터셋 논문
    - 데이터 제작에 관련된 디테일은 보통 Appendix에 나와 있음
    - TAC KBP 챌린지를 통해 얻은 데이터를 Mechanical Turk를 통해 annotation 진행
- KLUE: Korean Language Understanding Evaluation
    - KLUE 데이터셋 논문
    - Data Construction 부분에 데이터셋 제작 관련 정보가 수록
    - 위키피디아, 위키트리, 정부 정책 브리핑에서 원시 데이터를 수집 → 문어성이 짙음
    - TAC KBP와 유사하게 관계를 설정
    - 한국어 특성상 라벨링을 개편
    - Electra 기반 모델을 통해 개체명 추출
    - DeepNatural 크라우드 소싱 업체를 통해 라벨링

## 관계 추출 데이터 구축 실습

- 과제 정의
    - 고려할 요소
        - 목적, 규모, 원시 데이터, 라벨링 체계, 라벨링 도구, 형식, 검수, 평가 등
- 구축 프로세스 설계
    - 과제 정의 - 라벨링 대상 데이터 확보 - 가이드라인 작성 - 파일럿 구축 - 파일럿 검수 - 가이드라인 개정 - 본 구축 - 본 구축 검수 - 데이터 개정 - 데이터 완성
- 가이드라인 작성
    - 핵심 내용: 라벨링 작업을 위한 가이드라인
    - 작업 목적, 작업 도구 사용법, 작업 대상 문장과 아닌 것 구분 기준, 레이블별 주석 기준
    - 가이드라인이 너무 복잡하면 오히려 작업자가 가이드라인을 등한시 하는 경우도 있으니 주의

# 📄피어세션 정리

- 월: 강의
- 화: 오피스 아워
- 수: 두런두런
- 목: 라벨링 협의
- 금: 멘토링, 1차산출물 제작

# 🤔학습 회고

- 잘했던것, 좋았던것, 계속할것
    - 기민했던 신기술 체험과 도입, 마이크 새로 산 것
- 잘못했던것, 아쉬운것, 부족한것 -> 개선방향
    - 블로그 리뉴얼 아직 시작 못함→천천히 주말부터 시작, 삶의 지도 아직까지도 못 씀→조금씩 천천히 시작해보기
- 도전할 것, 시도할 것
    - github blog, 삶의 지도, 이력서
- 키워드(공부한 것,알게된 것, 느낀 점)
    - annotation, labeling, 인문학